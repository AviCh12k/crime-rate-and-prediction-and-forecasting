{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import random\n",
    "import nltk\n",
    "import string\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk import pos_tag\n",
    "from nltk.tokenize import word_tokenize,sent_tokenize\n",
    "from nltk.corpus import wordnet\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Text</th>\n",
       "      <th>Category</th>\n",
       "      <th>Time</th>\n",
       "      <th>Location</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Shri. Adesh Gupta ji President, BJP Delhi has ...</td>\n",
       "      <td>accident</td>\n",
       "      <td>2018-01-01</td>\n",
       "      <td>Laxmi Nagar</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Murders, rapes, cyber crime: How Covid affecte...</td>\n",
       "      <td>cyber crime</td>\n",
       "      <td>2018-01-01</td>\n",
       "      <td>Bhajanpura</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>The father killed his 10-year-old son along wi...</td>\n",
       "      <td>murder</td>\n",
       "      <td>2018-01-01</td>\n",
       "      <td>Mundka</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>RT @bainsindian: Madam Shiv Senni ho gayi hoðŸ¤”\\...</td>\n",
       "      <td>accident</td>\n",
       "      <td>2018-01-01</td>\n",
       "      <td>Sadar Bazar</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Â» Average 77 #rape cases daily reported in #In...</td>\n",
       "      <td>crime against women</td>\n",
       "      <td>2018-01-01</td>\n",
       "      <td>Shakarpur</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24510</th>\n",
       "      <td>Respected @narendramodi ji we consider u as ou...</td>\n",
       "      <td>accident</td>\n",
       "      <td>2018-12-31</td>\n",
       "      <td>Nihal Vihar</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24511</th>\n",
       "      <td>RT @matrixxmedia: An Indian woman allegedly as...</td>\n",
       "      <td>murder</td>\n",
       "      <td>2018-12-31</td>\n",
       "      <td>Nihal Vihar</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24512</th>\n",
       "      <td>Headless Body of Man Found in Plastic Bag in N...</td>\n",
       "      <td>murder</td>\n",
       "      <td>2018-12-31</td>\n",
       "      <td>Bawana</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24513</th>\n",
       "      <td>@DigitalShakti @NCWIndia @Facebook @AutobotInf...</td>\n",
       "      <td>cyber crime</td>\n",
       "      <td>2018-12-31</td>\n",
       "      <td>Bhajanpura</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24514</th>\n",
       "      <td>RT @apradhan1968: Dear @dtptraffic please take...</td>\n",
       "      <td>accident</td>\n",
       "      <td>2018-12-31</td>\n",
       "      <td>Vaishali</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>24515 rows Ã— 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    Text             Category  \\\n",
       "0      Shri. Adesh Gupta ji President, BJP Delhi has ...             accident   \n",
       "1      Murders, rapes, cyber crime: How Covid affecte...          cyber crime   \n",
       "2      The father killed his 10-year-old son along wi...               murder   \n",
       "3      RT @bainsindian: Madam Shiv Senni ho gayi hoðŸ¤”\\...             accident   \n",
       "4      Â» Average 77 #rape cases daily reported in #In...  crime against women   \n",
       "...                                                  ...                  ...   \n",
       "24510  Respected @narendramodi ji we consider u as ou...             accident   \n",
       "24511  RT @matrixxmedia: An Indian woman allegedly as...               murder   \n",
       "24512  Headless Body of Man Found in Plastic Bag in N...               murder   \n",
       "24513  @DigitalShakti @NCWIndia @Facebook @AutobotInf...          cyber crime   \n",
       "24514  RT @apradhan1968: Dear @dtptraffic please take...             accident   \n",
       "\n",
       "             Time     Location  \n",
       "0      2018-01-01  Laxmi Nagar  \n",
       "1      2018-01-01   Bhajanpura  \n",
       "2      2018-01-01       Mundka  \n",
       "3      2018-01-01  Sadar Bazar  \n",
       "4      2018-01-01    Shakarpur  \n",
       "...           ...          ...  \n",
       "24510  2018-12-31  Nihal Vihar  \n",
       "24511  2018-12-31  Nihal Vihar  \n",
       "24512  2018-12-31       Bawana  \n",
       "24513  2018-12-31   Bhajanpura  \n",
       "24514  2018-12-31     Vaishali  \n",
       "\n",
       "[24515 rows x 4 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('data.csv')\n",
    "df.drop(columns='Unnamed: 0', inplace = True)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['i',\n",
       " 'me',\n",
       " 'my',\n",
       " 'myself',\n",
       " 'we',\n",
       " 'our',\n",
       " 'ours',\n",
       " 'ourselves',\n",
       " 'you',\n",
       " \"you're\",\n",
       " \"you've\",\n",
       " \"you'll\",\n",
       " \"you'd\",\n",
       " 'your',\n",
       " 'yours',\n",
       " 'yourself',\n",
       " 'yourselves',\n",
       " 'he',\n",
       " 'him',\n",
       " 'his',\n",
       " 'himself',\n",
       " 'she',\n",
       " \"she's\",\n",
       " 'her',\n",
       " 'hers',\n",
       " 'herself',\n",
       " 'it',\n",
       " \"it's\",\n",
       " 'its',\n",
       " 'itself',\n",
       " 'they',\n",
       " 'them',\n",
       " 'their',\n",
       " 'theirs',\n",
       " 'themselves',\n",
       " 'what',\n",
       " 'which',\n",
       " 'who',\n",
       " 'whom',\n",
       " 'this',\n",
       " 'that',\n",
       " \"that'll\",\n",
       " 'these',\n",
       " 'those',\n",
       " 'am',\n",
       " 'is',\n",
       " 'are',\n",
       " 'was',\n",
       " 'were',\n",
       " 'be',\n",
       " 'been',\n",
       " 'being',\n",
       " 'have',\n",
       " 'has',\n",
       " 'had',\n",
       " 'having',\n",
       " 'do',\n",
       " 'does',\n",
       " 'did',\n",
       " 'doing',\n",
       " 'a',\n",
       " 'an',\n",
       " 'the',\n",
       " 'and',\n",
       " 'but',\n",
       " 'if',\n",
       " 'or',\n",
       " 'because',\n",
       " 'as',\n",
       " 'until',\n",
       " 'while',\n",
       " 'of',\n",
       " 'at',\n",
       " 'by',\n",
       " 'for',\n",
       " 'with',\n",
       " 'about',\n",
       " 'against',\n",
       " 'between',\n",
       " 'into',\n",
       " 'through',\n",
       " 'during',\n",
       " 'before',\n",
       " 'after',\n",
       " 'above',\n",
       " 'below',\n",
       " 'to',\n",
       " 'from',\n",
       " 'up',\n",
       " 'down',\n",
       " 'in',\n",
       " 'out',\n",
       " 'on',\n",
       " 'off',\n",
       " 'over',\n",
       " 'under',\n",
       " 'again',\n",
       " 'further',\n",
       " 'then',\n",
       " 'once',\n",
       " 'here',\n",
       " 'there',\n",
       " 'when',\n",
       " 'where',\n",
       " 'why',\n",
       " 'how',\n",
       " 'all',\n",
       " 'any',\n",
       " 'both',\n",
       " 'each',\n",
       " 'few',\n",
       " 'more',\n",
       " 'most',\n",
       " 'other',\n",
       " 'some',\n",
       " 'such',\n",
       " 'no',\n",
       " 'nor',\n",
       " 'not',\n",
       " 'only',\n",
       " 'own',\n",
       " 'same',\n",
       " 'so',\n",
       " 'than',\n",
       " 'too',\n",
       " 'very',\n",
       " 's',\n",
       " 't',\n",
       " 'can',\n",
       " 'will',\n",
       " 'just',\n",
       " 'don',\n",
       " \"don't\",\n",
       " 'should',\n",
       " \"should've\",\n",
       " 'now',\n",
       " 'd',\n",
       " 'll',\n",
       " 'm',\n",
       " 'o',\n",
       " 're',\n",
       " 've',\n",
       " 'y',\n",
       " 'ain',\n",
       " 'aren',\n",
       " \"aren't\",\n",
       " 'couldn',\n",
       " \"couldn't\",\n",
       " 'didn',\n",
       " \"didn't\",\n",
       " 'doesn',\n",
       " \"doesn't\",\n",
       " 'hadn',\n",
       " \"hadn't\",\n",
       " 'hasn',\n",
       " \"hasn't\",\n",
       " 'haven',\n",
       " \"haven't\",\n",
       " 'isn',\n",
       " \"isn't\",\n",
       " 'ma',\n",
       " 'mightn',\n",
       " \"mightn't\",\n",
       " 'mustn',\n",
       " \"mustn't\",\n",
       " 'needn',\n",
       " \"needn't\",\n",
       " 'shan',\n",
       " \"shan't\",\n",
       " 'shouldn',\n",
       " \"shouldn't\",\n",
       " 'wasn',\n",
       " \"wasn't\",\n",
       " 'weren',\n",
       " \"weren't\",\n",
       " 'won',\n",
       " \"won't\",\n",
       " 'wouldn',\n",
       " \"wouldn't\",\n",
       " '!',\n",
       " '\"',\n",
       " '#',\n",
       " '$',\n",
       " '%',\n",
       " '&',\n",
       " \"'\",\n",
       " '(',\n",
       " ')',\n",
       " '*',\n",
       " '+',\n",
       " ',',\n",
       " '-',\n",
       " '.',\n",
       " '/',\n",
       " ':',\n",
       " ';',\n",
       " '<',\n",
       " '=',\n",
       " '>',\n",
       " '?',\n",
       " '@',\n",
       " '[',\n",
       " '\\\\',\n",
       " ']',\n",
       " '^',\n",
       " '_',\n",
       " '`',\n",
       " '{',\n",
       " '|',\n",
       " '}',\n",
       " '~']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wordnet_lemmatizer = WordNetLemmatizer()\n",
    "stopwords = nltk.corpus.stopwords.words('english')\n",
    "stopwords+=list(string.punctuation)\n",
    "stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_simple_pos(tag):\n",
    "    if tag.startswith('J'):\n",
    "        return wordnet.ADJ\n",
    "    elif tag.startswith('V'):\n",
    "        return wordnet.VERB\n",
    "    elif tag.startswith('N'):\n",
    "        return wordnet.NOUN\n",
    "    elif tag.startswith('R'):\n",
    "        return wordnet.ADV\n",
    "    else:\n",
    "        return wordnet.NOUN\n",
    "\n",
    "def preprocess(sent):\n",
    "    clean_text = []\n",
    "    text = sent.split(\" \")\n",
    "    for i,s in enumerate(text):\n",
    "        if s.startswith('http') or s.startswith('@'):\n",
    "            text[i] = \"\";\n",
    "    if(text[0]=='RT'):\n",
    "        text[0]=\"\"\n",
    "        text[1]=\"\"\n",
    "    sent = \" \".join(text)\n",
    "    sent.strip()\n",
    "#     print(sent)\n",
    "    words = word_tokenize(sent)\n",
    "    pos = pos_tag(words)\n",
    "    for i,word in enumerate(words):\n",
    "        if word not in stopwords or word.lower() not in stopwords:\n",
    "            clean_word = wordnet_lemmatizer.lemmatize(word,pos=get_simple_pos(pos[i][1]))\n",
    "            clean_text.append(clean_word.lower())\n",
    "    return \" \".join(clean_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Text</th>\n",
       "      <th>Category</th>\n",
       "      <th>Time</th>\n",
       "      <th>Location</th>\n",
       "      <th>clean_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Shri. Adesh Gupta ji President, BJP Delhi has ...</td>\n",
       "      <td>accident</td>\n",
       "      <td>2018-01-01</td>\n",
       "      <td>Laxmi Nagar</td>\n",
       "      <td>shri adesh gupta ji president bjp delhi presen...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Murders, rapes, cyber crime: How Covid affecte...</td>\n",
       "      <td>cyber crime</td>\n",
       "      <td>2018-01-01</td>\n",
       "      <td>Bhajanpura</td>\n",
       "      <td>murders rape cyber crime how covid affect crim...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>The father killed his 10-year-old son along wi...</td>\n",
       "      <td>murder</td>\n",
       "      <td>2018-01-01</td>\n",
       "      <td>Mundka</td>\n",
       "      <td>the father kill 10-year-old son along wife gir...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>RT @bainsindian: Madam Shiv Senni ho gayi hoðŸ¤”\\...</td>\n",
       "      <td>accident</td>\n",
       "      <td>2018-01-01</td>\n",
       "      <td>Sadar Bazar</td>\n",
       "      <td>madam shiv senni ho gayi hoðŸ¤” mea already reach...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Â» Average 77 #rape cases daily reported in #In...</td>\n",
       "      <td>crime against women</td>\n",
       "      <td>2018-01-01</td>\n",
       "      <td>Shakarpur</td>\n",
       "      <td>Â» average 77 rape case daily report india 2020...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24510</th>\n",
       "      <td>Respected @narendramodi ji we consider u as ou...</td>\n",
       "      <td>accident</td>\n",
       "      <td>2018-12-31</td>\n",
       "      <td>Nihal Vihar</td>\n",
       "      <td>respected ji consider u head head family i â€™ a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24511</th>\n",
       "      <td>RT @matrixxmedia: An Indian woman allegedly as...</td>\n",
       "      <td>murder</td>\n",
       "      <td>2018-12-31</td>\n",
       "      <td>Nihal Vihar</td>\n",
       "      <td>an indian woman allegedly assault rap mumbai f...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24512</th>\n",
       "      <td>Headless Body of Man Found in Plastic Bag in N...</td>\n",
       "      <td>murder</td>\n",
       "      <td>2018-12-31</td>\n",
       "      <td>Bawana</td>\n",
       "      <td>headless body man found plastic bag navi mumba...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24513</th>\n",
       "      <td>@DigitalShakti @NCWIndia @Facebook @AutobotInf...</td>\n",
       "      <td>cyber crime</td>\n",
       "      <td>2018-12-31</td>\n",
       "      <td>Bhajanpura</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24514</th>\n",
       "      <td>RT @apradhan1968: Dear @dtptraffic please take...</td>\n",
       "      <td>accident</td>\n",
       "      <td>2018-12-31</td>\n",
       "      <td>Vaishali</td>\n",
       "      <td>dear please take note fall traffic signal gate...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>24515 rows Ã— 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    Text             Category  \\\n",
       "0      Shri. Adesh Gupta ji President, BJP Delhi has ...             accident   \n",
       "1      Murders, rapes, cyber crime: How Covid affecte...          cyber crime   \n",
       "2      The father killed his 10-year-old son along wi...               murder   \n",
       "3      RT @bainsindian: Madam Shiv Senni ho gayi hoðŸ¤”\\...             accident   \n",
       "4      Â» Average 77 #rape cases daily reported in #In...  crime against women   \n",
       "...                                                  ...                  ...   \n",
       "24510  Respected @narendramodi ji we consider u as ou...             accident   \n",
       "24511  RT @matrixxmedia: An Indian woman allegedly as...               murder   \n",
       "24512  Headless Body of Man Found in Plastic Bag in N...               murder   \n",
       "24513  @DigitalShakti @NCWIndia @Facebook @AutobotInf...          cyber crime   \n",
       "24514  RT @apradhan1968: Dear @dtptraffic please take...             accident   \n",
       "\n",
       "             Time     Location  \\\n",
       "0      2018-01-01  Laxmi Nagar   \n",
       "1      2018-01-01   Bhajanpura   \n",
       "2      2018-01-01       Mundka   \n",
       "3      2018-01-01  Sadar Bazar   \n",
       "4      2018-01-01    Shakarpur   \n",
       "...           ...          ...   \n",
       "24510  2018-12-31  Nihal Vihar   \n",
       "24511  2018-12-31  Nihal Vihar   \n",
       "24512  2018-12-31       Bawana   \n",
       "24513  2018-12-31   Bhajanpura   \n",
       "24514  2018-12-31     Vaishali   \n",
       "\n",
       "                                              clean_text  \n",
       "0      shri adesh gupta ji president bjp delhi presen...  \n",
       "1      murders rape cyber crime how covid affect crim...  \n",
       "2      the father kill 10-year-old son along wife gir...  \n",
       "3      madam shiv senni ho gayi hoðŸ¤” mea already reach...  \n",
       "4      Â» average 77 rape case daily report india 2020...  \n",
       "...                                                  ...  \n",
       "24510  respected ji consider u head head family i â€™ a...  \n",
       "24511  an indian woman allegedly assault rap mumbai f...  \n",
       "24512  headless body man found plastic bag navi mumba...  \n",
       "24513                                                     \n",
       "24514  dear please take note fall traffic signal gate...  \n",
       "\n",
       "[24515 rows x 5 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['clean_text'] = df['Text'].apply(lambda x:preprocess(x))\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import plot_confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(df['clean_text'], df['Category'], random_state = 0)\n",
    "tfidf_transformer = TfidfVectorizer()\n",
    "X_train_tfidf = tfidf_transformer.fit_transform(X_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Accuracy:  0.9607309909713913  Testing Accuracy:  0.957741882852015\n"
     ]
    }
   ],
   "source": [
    "nb = MultinomialNB().fit(X_train_tfidf, y_train)\n",
    "X_test_tfidf = tfidf_transformer.transform(X_test)\n",
    "print('Training Accuracy: ',nb.score(X_train_tfidf, y_train),' Testing Accuracy: ',nb.score(X_test_tfidf, y_test))\n",
    "# y_pred = clf.predict(X_test_tfidf)\n",
    "# plot_confusion_matrix(clf,y_test,y_pred)\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Accuracy:  0.9781355379092788  Testing Accuracy:  0.9751998694729972\n"
     ]
    }
   ],
   "source": [
    "lr = LogisticRegression(solver='liblinear', C=10.0).fit(X_train_tfidf, y_train)\n",
    "X_test_tfidf = tfidf_transformer.transform(X_test)\n",
    "print('Training Accuracy: ',lr.score(X_train_tfidf, y_train),' Testing Accuracy: ',lr.score(X_test_tfidf, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Accuracy:  0.9781355379092788  Testing Accuracy:  0.973568281938326\n"
     ]
    }
   ],
   "source": [
    "dt = DecisionTreeClassifier().fit(X_train_tfidf, y_train)\n",
    "X_test_tfidf = tfidf_transformer.transform(X_test)\n",
    "print('Training Accuracy: ',dt.score(X_train_tfidf, y_train),' Testing Accuracy: ',dt.score(X_test_tfidf, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Accuracy:  0.9781355379092788  Testing Accuracy:  0.9745472344591287\n"
     ]
    }
   ],
   "source": [
    "rf = RandomForestClassifier().fit(X_train_tfidf, y_train)\n",
    "X_test_tfidf = tfidf_transformer.transform(X_test)\n",
    "print('Training Accuracy: ',rf.score(X_train_tfidf, y_train),' Testing Accuracy: ',rf.score(X_test_tfidf, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Accuracy:  0.9780811487000979  Testing Accuracy:  0.9755261869799314\n"
     ]
    }
   ],
   "source": [
    "svm = SVC().fit(X_train_tfidf, y_train)\n",
    "X_test_tfidf = tfidf_transformer.transform(X_test)\n",
    "print('Training Accuracy: ',svm.score(X_train_tfidf, y_train),' Testing Accuracy: ',svm.score(X_test_tfidf, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# trend basis - All except murder\n",
    "# location basis = murder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
